{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"The Real-Timers Guide to the Computational Galaxy","text":"<p>A guide designed for both deep learners and systems programmers. Meant to be followed several times at deepening levels. The material is comprised of 6 modules.</p> <ul> <li>Intro to the course, the different ways to use the material, intro to Rust and wgpu.</li> <li>Memory hierarchies and computational graphs</li> <li>Parallelization, interactivity, events and GUIs</li> <li>Types, energy usage and inference, quantization, sparsity and pruning of neural networks</li> <li>Introduction to profiling, optimization use cases on topics such as model training and quantization, graphics, computer vision</li> <li>How to create real time systems, frameworks for the different fields and project proposals</li> </ul>"},{"location":"#todo","title":"TODO","text":"<ul> <li>Try rust-nexttest to solve the testing issue</li> <li>Find the right benchmarking and performance tools (blessed.rs)</li> <li>Look into friendlier error handling? Perhaps logging instead of panicing to get students used to logging. Introduce anyhow for better error handling?</li> <li>Loom</li> </ul>"},{"location":"#references-and-additional-reading","title":"References and additional reading","text":"<p>High Performance Machine Learning High Performance Machine Learning Flash Attention Branchless Programming The Rust Programming Language Learn wgpu Install Rust wgpu ShaderToy Inigo Quilez ORB-SLAM ORB-SLAM2 Z-order curves Linearised Trees on the GPU Vivienne Sze - Energy Efficient AI Visual Computing - Stanford Parallel Computing - Stanford Rust Profiling RenderDoc Book of Shaders Scratchapixel Ray Tracing in One Weekend Physically Based Rendering Crafting Interpreters</p>"},{"location":"code/","title":"Code","text":""},{"location":"code/#installation","title":"Installation","text":"<ul> <li>Install Rust. A version of Rust supporting edition 2021 is needed.</li> <li>git clone this code</li> <li>In the command line write <code>cargo run --release</code>. This might take a while.</li> <li>For IDE, I prefere VS Code with the extensions rust-analyzer, CodeLLDB, Rust Syntax, WGSL, wgsl-analyzer and optionally Dracula For Rust Theme.</li> </ul>"},{"location":"code/#testing","title":"Testing","text":"<p>On some computers the GPU tests will currently fail unless being run with <code>cargo test -- --test-threads=1</code> Even then it might fail. You can just try a few more times or try to run tests individually. It is because of the queue and device being acquired several times. This is likely to happen less on bigger GPU's.</p>"},{"location":"overview/","title":"Summary of course content","text":""},{"location":"m0_introduction/","title":"Introduction","text":"<ul> <li>Why should you use this material</li> <li>How to use the materials as a student and a teacher.</li> <li>Which level is for who and what does it require</li> </ul>"},{"location":"m0_introduction/#intro-to-computing","title":"Intro to Computing","text":"<ul> <li>Scripting</li> <li>Compilers</li> </ul>"},{"location":"m0_introduction/#intro-to-rust","title":"Intro to Rust","text":"<ul> <li>Why Rust?</li> <li>Project setup</li> <li>How to compile</li> <li>What are types</li> <li>Borrow checker - shared and mutable references</li> <li>Move, Copy and Clone</li> <li>Iterators</li> <li>(Iterators - slightly more detailed)</li> <li>Option, Result - everywhere</li> <li>Enums &amp; Match statements</li> <li>(Smart pointers)</li> <li>(Traits)</li> <li>(Clippy)</li> <li>(fmt)</li> <li>Frequent commands and FAQ</li> </ul>"},{"location":"m1_memory_hierarchies/","title":"Memory Hierarchies, Computational Graphs and Compilers","text":""},{"location":"m1_memory_hierarchies/s0_overview/overview/","title":"Overview","text":""},{"location":"m1_memory_hierarchies/s1_intro/intro/","title":"Intro","text":"<ul> <li>Why memory hierarchies and computational graphs?</li> <li>Intro to the code framework</li> </ul>"},{"location":"m1_memory_hierarchies/s1_intro/intro/#getting-started","title":"Getting Started","text":"<p>The code framework has benchmarking and functions. Most of them are variations of the same operators.</p>"},{"location":"m1_memory_hierarchies/s2_memory_hierarchies_and_the_cpu/memory_hierarchies_and_the_cpu/","title":"Memory Hierarchies and the CPU","text":"<ul> <li>Intro to memory hierarchies</li> <li>(Virtualized memory)</li> <li>Pointers, Heap and Stack, Dynamic Arrays</li> <li>The CPU-side memory hierarchies</li> <li>Pipelines and branch prediction</li> <li>Inlining</li> <li>(Pointers and smart pointers)</li> <li>(Garbage collectors)</li> </ul>"},{"location":"m1_memory_hierarchies/s3_computational_graphs/computational_graphs/","title":"S3 - Computational Graphs","text":""},{"location":"m1_memory_hierarchies/s3_computational_graphs/computational_graphs/#computational-graphs","title":"Computational Graphs","text":"<ul> <li>Intro to computational graphs - overview of immediate, graph and compiled graph</li> <li>The network we want to support</li> <li>What's in a tensor</li> <li>Data dependencies and control dependencies</li> <li>(Intermediate representations)</li> <li>(Compiler verifications and the restrict keyword)</li> <li>Testing the correctness of the nodes</li> <li>(Graph representations)</li> <li>(Perspective to render graphs)</li> </ul>"},{"location":"m1_memory_hierarchies/s4_intro_to_gpus/intro_to_gpus/","title":"Intro to GPU's","text":"<ul> <li>Brief intro to GPU's</li> <li>(Shared memory, warp shuffling and distributed shared memory)</li> <li>(Synchronization)</li> <li>(SPIR-V &amp; GLSL/HLSL)</li> <li>Intro to wgpu</li> <li>(Setup of wgpu)</li> </ul>"},{"location":"m1_memory_hierarchies/s5_immediate_gpu_computation/immediate_gpu_computation/","title":"Immediate GPU computation","text":"<ul> <li>Building the first compute node</li> <li>GPU's in greater detail</li> <li>Pipelining, Warp Divergence, Occupancy and Overlap</li> <li>Building the remaining compute nodes</li> <li>Testing the whole thing in immediate mode</li> <li>(Caching shaders)</li> </ul>"},{"location":"m1_memory_hierarchies/s6_building_a_computational_graph/building_a_computational_graph/","title":"Building a Computational Graph","text":"<ul> <li>Seeing the CPU-GPU memory hierarchies</li> <li>Transfers</li> <li>Building a computational graph</li> <li>Testing the computational graph</li> </ul>"},{"location":"m1_memory_hierarchies/s7_computational_graph_compilers/computational_graph_compilers/","title":"Building a Computational Graph Compiler","text":"<ul> <li>Seeing the GPU memory hierarchy - caches, shared memory and RAM</li> <li>Graph compilers and OP codes</li> <li>Swapping operators for fused versions</li> <li>Building a graph compiler</li> <li>Testing the graph compiler</li> <li>(Metaprogramming - Shaders are just strings!)</li> <li>(Decomposing to OP codes)</li> <li>(A toy example with OP codes)</li> <li>(Additional ideas for compiler optimization, buffer reusage, matrix reusage)</li> </ul>"},{"location":"m1_memory_hierarchies/s8_closing/closing/","title":"Closing Remarks","text":"<ul> <li>Comparing CPU, immediate, immediate with shader caching, computational graph and compiled computational graph.</li> <li>How does this relate to torch.compile?</li> <li>Where to go from here?</li> </ul>"},{"location":"m1_memory_hierarchies/s9_exercises/exercises/","title":"Exercises - do at least 1","text":"<p>These are only for levels 3 and 4</p> <ul> <li>Implement a version of the linear layer functions which uses shared memory and tiling</li> <li>Implement the tree reduction version of the sum function and add it to the softmax function. Also compare the single pass and the tree reduction performance graphs. Reference</li> <li>Implement a max pooling operator in all levels and implement tests</li> <li>Implement a convolution operator in all levels and implement tests</li> <li>Add reusable buffers to the computational graph system</li> <li>Extend the computational graph with inplace operation for the ReLU operator</li> </ul>"},{"location":"m2_concepts_in_parallelism/","title":"Concepts in Parallelism","text":""},{"location":"m2_concepts_in_parallelism/#parallelism-interactivity-events-and-guis","title":"Parallelism, interactivity, events and GUIs","text":"<ul> <li>Data parallelism, work stealing - rayon</li> <li>Data parallelism, non-work stealing - crossbeam</li> <li>Mutex</li> <li>Async</li> <li>Atomic</li> <li>Threads</li> <li>GPU</li> <li>(Sparsity)</li> <li>(Random Access and Monte Carlo (Gyro Dropout))</li> <li>(Branchless programming)</li> <li>(SIMD)</li> <li>(Sorting)</li> <li>Channels</li> <li>Events</li> <li>Key and Mouse events</li> <li>Event Loops</li> <li>(GUIs &amp; egui)</li> <li>(Examine egui-winit-wgpu template)</li> <li>(Graph representations - pointers and indices)</li> <li>(Trees using indices)</li> <li>(Parallel work on graphs)</li> </ul>"},{"location":"m2_concepts_in_parallelism/#specializationsexercise-pick-items-worth-a-total-of-3-points-or-more-write-a-10-lines-interpretation-of-each-item","title":"(Specializations/Exercise - Pick items worth a total of 3 points or more, write a 10+ lines interpretation of each item)","text":"<ul> <li>(1 - Data-oriented design - Entity component systems)</li> <li>(1 - Array of Structs, Structs of Arrays, Auto-Vectorization)</li> <li>(1 - Linearized octrees)</li> <li>(2 - Sorting kernels in divergent workloads - Wavefront path tracing)</li> <li>(4 - ORB-SLAM - design and a warning about trying to code it)</li> <li>(4 - Nanite)</li> <li>(1 - PyTorch - Data-Distributed-Parallelism)</li> <li>(1 - PyTorch - Model-Distributed-Parallelism)</li> <li>(2 - Shadertoy)</li> <li>(1 - Gyro Dropout - MLSys 2022)</li> <li>(1 - Hierarchical Frustum Culling)</li> <li>(2 - Flash Attention)</li> <li>(2 - Custom memory allocators)</li> <li>(2 - JAX)</li> </ul>"},{"location":"m2_concepts_in_parallelism/#exercise","title":"(Exercise)","text":"<ul> <li>Describe the base architecture of the egui-winit-wgpu template. Expand on the template and program some things (needs suggestions) using some of the primitives introduced in the module</li> </ul>"},{"location":"m3_types/","title":"Types","text":""},{"location":"m3_types/#types-energy-usage-and-inference-quantization-sparsity-and-pruning-of-neural-networks","title":"Types, energy usage and inference, quantization, sparsity and pruning of neural networks","text":"<ul> <li>Floats</li> <li>Float precision</li> <li>(Fast inverse square root)</li> <li>Integers</li> <li>(Bit tricks)</li> <li>(Basic compression)</li> <li>Energy usage</li> <li>(Batch based data processing)</li> <li>Inference</li> <li>Quantization</li> <li>Sparsity</li> <li>Pruning</li> <li>(Tensor Cores)</li> <li>(Using integers instead of strings in hash tables)</li> </ul>"},{"location":"m3_types/#specializations-group-discussion-and-presentation","title":"(Specializations - Group discussion and presentation)","text":"<ul> <li>(Packing bits for atomic operators)</li> <li>(Inverse depth buffers)</li> <li>(Bittricks, packing normals and colors)</li> <li>(Morton codes / Z-order curves, tiling and GPU textures)</li> <li>(Calculating compression precision in a lossy point cloud compression scheme)</li> <li>(DLSS)</li> <li>(Real-Time Texture Decompression and Upsampling)</li> <li>(2:4 sparsity with Tensor Cores)</li> </ul>"},{"location":"m3_types/#exercise","title":"(Exercise)","text":"<ul> <li>(Find a suitable model and inference library. Perform inference. Optimize the model and inference process. Can you do inferencing on one thread, training on another and swap in the new model? ADD SUGGESTED MODELS)</li> </ul>"},{"location":"m4_profilers/","title":"Profilers and Case Studies","text":""},{"location":"m4_profilers/#introduction-to-profiling-optimization-case-studies","title":"Introduction to profiling, Optimization case studies","text":"<ul> <li>Profilers (PyTorch, web, GPU, general)</li> </ul>"},{"location":"m4_profilers/#specializations","title":"Specializations","text":"<ul> <li>Training a neural network</li> <li>Optimizing a neural network for inference</li> <li>Running Yolo</li> <li>Optimizing a point cloud renderer</li> <li>Optimizing a path tracer</li> </ul>"},{"location":"m4_profilers/#exercise","title":"(Exercise)","text":"<ul> <li>(Try out the profilers relevant to your own system with some sample programs.)</li> </ul>"},{"location":"m5_projects/","title":"Projects","text":"<p>This whole module is for levels 3 and 4</p>"},{"location":"m5_projects/#how-to-create-real-time-systems-good-frameworks-for-the-different-fields-and-project-proposals","title":"How to create real time systems, good frameworks for the different fields and project proposals","text":"<ul> <li>Starting with a simple prototype</li> <li>Identify your components</li> <li>Single threaded correct implementation -&gt; Testing to avoid regression</li> <li>Optimize</li> </ul>"},{"location":"m5_projects/#tips-and-tricks-in-real-time-systems","title":"Tips and tricks in real time systems","text":"<ul> <li>memcpy</li> <li>Hot loops, event loops</li> <li>Allocations in a hot loop</li> <li>System calls - hoist out of the hot loop</li> <li>Logging and printing</li> <li>Bindings - PyO3 and cxx</li> <li>Walk, don't run, testing for correctness before optimization</li> <li>Don't use abbreviations</li> <li>Don't use postfix incrementation++</li> <li>When to care about software engineering and when to care about performance</li> <li>Don't use a string key/identifier or integer, when a type safe enum will do the job</li> <li>Hard coding types</li> <li>Cognitive load, and delaying errors to after the first draft - deliberate development vs. debugging</li> <li>Prefer stateless programming, minimize stateful programming (functional inspiration)</li> <li>Implicit casting</li> <li>Compression</li> <li>Know your system - mobile, laptop, desktop, integrated memory, which GPU</li> <li>Use version control even for solo development</li> <li>Am I copying/cloning things that don't need to be copied?</li> <li>Check/validate everything before the hot loop</li> <li>Anything that can be immutable, should be immutable - aliasing!</li> <li>Testing and Seeding RNG's</li> <li>Faster RNG </li> <li>Timing real-time systems and how to escape or offload compute</li> <li>Multi-resolution computing for making your real-time target</li> <li>Pressure testing and worst cases</li> </ul>"},{"location":"m5_projects/#components-librariesframeworks","title":"Components - libraries/frameworks","text":"<p>blessed rayon egui wonnx tch winit cv ultraviolet arewelearningyet burn </p>"},{"location":"m5_projects/#specializations-project-proposals","title":"Specializations - Project proposals","text":"<ul> <li>Virtual 3D scanner for a point cloud dataset</li> <li>EEG system</li> <li>Change the latent variables in a network using GUI, optimize the network</li> <li>Point cloud renderer</li> <li>Real-time style transfer on a web cam feed</li> <li>Rendering fractals influenced by a web cam feed</li> <li>Eye tracking -&gt; Present to screen and read from web cam -&gt; feature extraction -&gt; classifier -&gt; intervention signal -&gt; reading app (Wolfgang Fuhl, PISTOL, fixation detection)</li> <li>Bird classification from sound / Real-time classification of sound (Xeno-canto database)</li> <li>Who is talking? Real-time classification of sound</li> <li>Are you dyslexic? Eye tracking classifier</li> <li>Cognitive load tracker - Eyes &amp; pupil dilation and online estimation of signal strength (pupils vs. sound for the hearing impaired)</li> </ul>"},{"location":"m5_projects/#what-makes-for-a-good-project","title":"What makes for a good project?","text":"<ul> <li>What is your concept/project?</li> <li>Which concepts from the previous material do you think are relevant to your project and why?</li> <li>Preprocessing your data?</li> <li>How do you adapt to your chosen/available platform?</li> <li>Which libraries did you choose for this problem?</li> <li>How fast did you get to your minimum viable product?</li> <li>Which steps did you take from there and why?</li> <li>How did you determine which parts of your system to optimize?</li> <li>What else would you like to do with your system?</li> </ul>"}]}