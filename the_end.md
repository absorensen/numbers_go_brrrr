# The End

In the very beginning of this guide, I presented you with some performance gobbledigook, which you may or may
not have understood. What about now?

<figure markdown>
![Image](../figures/do_you_understand_this.png){ width="800" }
<figcaption>
<a href="https://burn.dev/docs/burn/"> Image credit </a>
</figcaption>
</figure>

Thank you for sticking with it and getting all the way to the end of this. Take a moment to enjoy the fact that you
accomplished something -

ðŸŒŒ [Queue Eric Idle!][0] ðŸŒŒ

In case you feel like learning more; where to from here?

Before I answer that, just one aside. It is very easy to just absolutely wear yourself
out doing courses like these online in your free time. Look out for yourself. You won't
learn much if you're burnt out. I have been there more than once. Please take care of yourself!

## Machine Learning Operations
If you feel like you dipped your toes into efficiency and you want to keep dipping your toes
into new stuff that will make you an overall better engineer, I can't recommend Nicki
Skafte Detlefsen's course [Machine Learning Operations][5] enough. In fact, I ripped off
his website to create this one (with his permission). In it you will learn software engineering
principles applicable to AI development such as repoducibility and deployment. It's also my
recommendation which contains more memes than this site. Which is something we should all
aspire to.

## Machine Learning Systems
If you want to learn more about optimizing machine learning systems - this [online book][4] written,
edited and curated by Vijay Janapa Reddi looks to be a very extensive resource, still under
rapid development.

## Visual Computing Systems
Kayvon Fatahalian has a wonderful course up on visual computing systems which combines topics
from graphics, computer vision, image analysis and deep learning. Specifically, focused on the
systems used in those fields. You can the most recent version [here][1]. The topics included
seem to change from year to year. It can definitely be worth it to go back and see which topics
were included in earlier years, through his [teaching website][2]. It's worth noting however,
that this course is fairly advanced and if you want to do the exercises you should probably
be familiar with C++.

## Parallel Computing
In the same vein, Kayvon Fatahalian and Kunle Olukotun have a course on parallel computing.
If you want a more thorough and academically rigorous introduction to parallelism, GPU's
and memory hierarchies it is available [here][3]. Do note that you probably need to be familiar
with C++ to do the exercises.

## TinyML and Efficient Deep Learning Computing
If you are more into video resources, the course [TinyML and Efficient Deep Learning Computing][6]
by Song Han contains both exercises, slides and videos for a wide look at more
efficient deep learning.

[0]: https://www.youtube.com/watch?v=buqtdpuZxvk
[1]: https://gfxcourses.stanford.edu/cs348k/spring24
[2]: https://graphics.stanford.edu/~kayvonf/
[3]: https://gfxcourses.stanford.edu/cs149/fall24
[4]: https://mlsysbook.ai/
[5]: https://skaftenicki.github.io/dtu_mlops/
[6]: https://efficientml.ai
